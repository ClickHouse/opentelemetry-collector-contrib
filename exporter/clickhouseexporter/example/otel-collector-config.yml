receivers:
  filelog:
    start_at: beginning
#    storage: file_storage
    include:
      - /tmp/clickhouse-server.log.short
#    operators:
#      - id: get-format
#        routes:
#          - expr: body matches "^\\{"
#            output: parser-docker
#          - expr: body matches "^[^ Z]+ "
#            output: parser-crio
#          - expr: body matches "^[^ Z]+Z"
#            output: parser-containerd
#        type: router
#      - id: parser-crio
#        output: extract_metadata_from_filepath
#        regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
#        timestamp:
#          layout: "2006-01-02T15:04:05.000000000-07:00"
#          layout_type: gotime
#          parse_from: attributes.time
#        type: regex_parser
#      - id: parser-containerd
#        output: extract_metadata_from_filepath
#        regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
#        timestamp:
#          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
#          parse_from: attributes.time
#        type: regex_parser
#      - id: parser-docker
#        output: extract_metadata_from_filepath
#        timestamp:
#          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
#          parse_from: attributes.time
#        type: json_parser
#      - id: extract_metadata_from_filepath
#        parse_from: attributes["log.file.path"]
#        regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$
#        type: regex_parser
#      - from: attributes.stream
#        to: attributes["log.iostream"]
#        type: move
#      - from: attributes.container_name
#        to: resource["k8s.container.name"]
#        type: move
#      - from: attributes.namespace
#        to: resource["k8s.namespace.name"]
#        type: move
#      - from: attributes.pod_name
#        to: resource["k8s.pod.name"]
#        type: move
#      - from: attributes.restart_count
#        to: resource["k8s.container.restart_count"]
#        type: move
#      - from: attributes.uid
#        to: resource["k8s.pod.uid"]
#        type: move
#      - from: attributes.log
#        to: body
#        type: move


# Error code regex: [A-Z][A-Z0-9]+_[A-Z0-9_]+
processors:
  loghouse: { }
#  logstransform:
#    operators:
#      - type: regex_parser
#        regex: '(?<exception>[A-Z][A-Z0-9]+_[A-Z0-9_]+)'
#        clickhouse_exception:
#          parse_from:
#            body.exception
  transform:
    log_statements:
      - context: resource
        statements:
          - set(attributes["k8s.container.name"], "c-teal-x-y-43-server")
          - set(attributes["app"], "") where attributes["app"] == nil
          - set(attributes["app"], "clickhouse-server") where IsMatch(attributes["k8s.container.name"], "^c-.+-server$")
          - set(attributes["app"], "clickhouse-keeper") where IsMatch(attributes["k8s.container.name"], "^c-.+-keeper$")
      - context: log
        statements:
          - merge_maps(attributes, ExtractPatterns(body, "(?P<exception>[A-Z][A-Z0-9]+_[A-Z0-9_]+)"), "insert")
          - set(severity_text, "TRACE") where IsMatch(body, "[<]Trace[>]") == true
          - set(severity_text, "DEBUG") where IsMatch(body, "[<]Debug[>]") == true
          - set(severity_text, "INFO") where IsMatch(body, "[<]Info(rmation(al)?)?[>]")
            == true
          - set(severity_text, "WARN") where IsMatch(body, "[<]Warn(ing)?[>]") == true
          - set(severity_text, "ERROR") where IsMatch(body, "[<]Error[>]") == true
          - set(severity_text, "FATAL") where IsMatch(body, "[<]Fatal[>]") == true
          - merge_maps(attributes, ParseJSON(body), "insert") where IsMatch(body, "^\\s*[{].+?[}]\\s*$")
            == true
          - set(body, attributes["msg"]) where attributes["msg"] != nil
          - set(body, attributes["message"]) where attributes["message"] != nil
          - delete_key(attributes, "msg") where body == attributes["msg"]
          - delete_key(attributes, "message") where body == attributes["message"]
          - set(severity_text, ConvertCase(attributes["level"], "upper")) where IsMatch(attributes["level"],
            "(?i)^(trace|debug|info|warn|error|fatal)$") == true
          - delete_key(attributes, "level") where attributes["level"] != nil and severity_text
            == ConvertCase(attributes["level"], "upper")
  batch:
    send_batch_size: 10
    timeout: 2s
#  memory_limiter:
#    check_interval: 2s
#    limit_mib: 1800
#    spike_limit_mib: 500
#  resourcedetection/system:
#    detectors: [ "system" ]
#    system:
#      hostname_sources: [ "os" ]
#  resource:
#    attributes:
#      - key: service.name
#        value: "serviceName"
#        action: upsert
exporters:
  clickhouse:
    create_db_and_tables: true
    endpoint: http://clickhouse:8123
    database: otel
    logs_table_name: otel_logs_1
    traces_table_name: otel_traces
    connection_params:
      async_insert: 1
      wait_for_async_insert: 0
    ttl_days: 1
    timeout: 10s
    sending_queue:
      queue_size: 100
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
extensions:
#  file_storage:
#    directory: /var/lib/otelcol
  health_check:
  pprof:
  zpages:

service:
  extensions:
    - pprof
    - zpages
    - health_check
#    - file_storage
  pipelines:
    logs:
      receivers: [  filelog ]
      processors: [  loghouse, transform, batch ]
      exporters: [ clickhouse ]
